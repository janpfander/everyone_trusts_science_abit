# Experiment 4 {#exp4}

Study 4 relies on broadly the same design as study 3, and is again run on a sample of participants with vaccine-skeptic beliefs. The main difference is that study 4 uses a set of science questions which, instead of being on well-established facts, we are about more recent discoveries (Table \@ref(tab:exp4-knowledge)). Our main question is whether participants will nevertheless readily accept the scientific consensus, as they did for the basic facts in previous studies.

As for the previous studies, we had the following hypotheses:

**H1a: Higher trust in science is associated with more science knowledge?**

**H1b: Higher trust in science is associated with more acceptance of the scientific consensus.**

**H2a: Higher conspiracy thinking is associated with less science knowledge?**

**H2b: Higher conspiracy thinking is associated with less acceptance of the scientific consensus.**

We had the following research questions:

**RQ1: What is the average science knowledge score?**

**RQ2: What is the average acceptance of the scientific consensus**

**RQ3: What reasons do participants provide to justify their rejection of the scientific consensus?**

**RQ4: In case they agree with the scientific consensus, do people feel that this is because of trust?**

## Participants

We recruited a sample of participants holing vaccine-skeptic beliefs. Prolific Academic allows to filter out participants who have given specific answers to certain questions. We selected three available questions: 1. "Participants were asked the following question: Please describe your attitudes towards the COVID-19 (Coronavirus) vaccines: [For (I feel positively about the vaccines); Against (I feel negatively about the vaccines); Neutral (I don't have strong opinions either way); Prefer not to say"]. We selected particpants who answered "Against". 2. "Participants were asked the following question: Have you received a coronavirus (COVID-19) vaccination? [Yes (at least one dose); No; Prefer not to answer]". We select only people who answered "No". 3. "Participants were asked the following question: On a scale from 1-7, please rate to what extent you agree with the following statement: I believe that scheduled immunizations are safe for children. [1 (TOTALLY DISAGREEE); 2 (DISAGREE); 3 (SOMEWHAT DISAGREE); 4 (NEITHER AGREE NOR DISAGREE); 5 (SOMEWHAT AGREE); 6 (AGREE); 7 (TOTALLY AGREE); Rather not say"]. We select only people who answered "1", "2", or "3". 

Based on these criteria, we recruited 200 participants from the US via prolific, of which two failed our attention check, resulting in a final sample of `r exp4_descriptives$n_subj` participants (`r exp4_descriptives$gender$female$n` female, `r exp4_descriptives$gender$male$n` male; $age_\text{mean}$: `r exp4_descriptives$age$mean`, $age_\text{sd}$: `r exp4_descriptives$age$sd`, $age_\text{median}$: `r exp4_descriptives$age$median`). Since we did not have any prior assumptions on effect sizes and our analyses were descriptive, we did not do a power analysis.

## Procedure

The procedure was identical to the one in experiment 3.

## Materials

\FloatBarrier

Table \@ref(tab:exp4-knowledge) shows all questions, their scientifically consensual answer, and their source. All but two questions were selected from existing science knowledge questionnaires. We tried to select non-political questions.

```{r exp4-knowledge}
# Function to replace special characters in all cells of a data frame
replace_special_characters <- function(df) {
  df %>%
    mutate(across(everything(), ~ gsub("\u2013|\u2014|\u2212", "-", .))) %>% # Replace en-dash, em-dash, and Unicode minus with ASCII hyphen-minus
    mutate(across(everything(), ~ iconv(., from = "UTF-8", to = "ASCII//TRANSLIT"))) # Ensure all text is ASCII
}

items <- read_csv("exp_4/materials/questions_study4.csv") 

# Replace special characters
items_cleaned <- replace_special_characters(items) %>% 
  mutate(id = 1:nrow(.)) %>%
  select(id, everything())  # Ensure 'id' is the first column

# Output the table
kbl(items_cleaned, booktabs = T, longtable = TRUE,
    caption = "Science knowledge items", full_width = T) %>%
  kable_styling(font_size = 8) %>%
  column_spec(1, width = "1em") %>%
  column_spec(2, width = "12em") %>%
  column_spec(3, width = "10em") %>%
  column_spec(4, width = "12em")
```

## Results

By contrast to previous studies on basic science knowledge, participants on average answered only  `r exp4_descriptives$means$knowledge_mean` (sd = `r exp4_descriptives$means$knowledge_sd`) of the questions correctly (RQ1). Similar with previous studies, however, they initially accepted the scientific consensus on average for `r exp4_descriptives$means$acceptance_initial_mean` (sd = `r exp4_descriptives$means$acceptance_initial_sd`) of the questions (RQ2). The acceptance rate is even higher when accounting for opinion revisions towards acceptance of the consensus, after initial rejection (`r exp4_descriptives$means$acceptance_mean`, sd = `r exp4_descriptives$means$acceptance_sd`).

Fig. \@ref(fig:exp4-conditional-acceptance) illustrates the relationship between knowledge and acceptance. In most cases (`r exp4_descriptives$conditional_acceptance$false$acceptance_initial$Yes$share`), participants readily accepted the scientific consensus right after having given the wrong answer to a question. After providing the chance to revise the initial consensus rejection, this share is even larger (`r exp4_descriptives$conditional_acceptance$false$acceptance$Yes$share`). In few (but still perhaps surprisingly many) cases (`r exp4_descriptives$conditional_acceptance$true$acceptance_initial$No$share`), participants who initially gave the correct response afterwards rejected the scientific consensus right after, thereby contradicting their own initial response. This share drops slightly after providing the chance to revise the initial consensus rejection (`r exp4_descriptives$conditional_acceptance$true$acceptance$No$share`).

For all correlations, we include opinion revisions for measuring consensus acceptance. We find no statistically significant correlation between science knowledge and trust in science (r = `r exp4_descriptives$cor_trust_knowledge$estimate`, p `r exp4_descriptives$cor_trust_knowledge$p.value`), but a small positive correlation between acceptance of scientific consensus and trust in science (r = `r exp4_descriptives$cor_trust_acceptance$estimate`, p `r exp4_descriptives$cor_trust_acceptance$p.value`). Again, these findings might be partly due to ceiling effects: As illustrated in Fig. \@ref(fig:exp4-plot), (i) most people do trust science, and (ii) that is true even among people with low knowledge or acceptance rates. We do not find a statistically significant correlation between neither conspiracy thinking and science knowledge (r = `r exp4_descriptives$cor_conspiracy_knowledge$estimate`, p `r exp4_descriptives$cor_conspiracy_knowledge$p.value`), nor between conspiracy thinking and acceptance of scientific consensus (r = `r exp4_descriptives$cor_conspiracy_acceptance$estimate`, p `r exp4_descriptives$cor_conspiracy_acceptance$p.value`).

For RQ3, we got `r exp4_descriptives$justifications_n` answers from `r exp4_descriptives$justifications_n_participants` different participants to the open-ended questions on why they had rejected the scientific consensus on a particular question. Table \@ref(tab:exp4-justifications) summarizes these answers by five categories.

All answers can be read in the appendix.

```{r exp4-justifications}
exp4_justifications %>%
  group_by(category)%>%
  summarize(n = n(), 
            n_subjects = n_distinct(id)) %>%
  mutate(Share = n/sum(n)) %>%
  mutate_if(is.numeric, round, digits=3) %>% 
  mutate(Share = paste0(Share*100, "%")) %>% 
  arrange(desc(n)) %>% 
  select(category, n, Share, n_subjects) %>% 
  rename(Category = category,
         `N (instances)` = n, 
         `Share (instances)` = Share, 
         `N (unique participants)` = n_subjects
         ) %>% 
  apa_table(caption = "Justifications by category")
```

For RQ4, only `r exp4_descriptives$acceptance_by_reason[["trust in scientists"]]$share` of participants said they accepted the scientific consensus because they trust scientists on this question, while `r exp4_descriptives$acceptance_by_reason[["independent verification"]]$share` said they independently verified the fact. `r exp4_descriptives$acceptance_by_reason[["other"]]$share` answered with other "other" and gave an open-ended explanation (see below for all open-ended answers). 

We also asked all `r exp4_descriptives$reason_followup_n` participants who answered that they had independently verified the answer to explain how they did so. The open-ended answers are listed below.

## Comparing items

### Conspiracy theories

Table \@ref(tab:exp4-correlation-conspiracy) shows the correlations of the three different scales assessing conspiracy thinking.

```{r exp4-correlation-conspiracy}
correlation_matrix <- exp4_wide %>%
  select(BCTI_avg, CMQ_avg, SICBS) %>% 
  rename(BCTI = BCTI_avg, 
         CMQ = CMQ_avg) %>% 
  cor()

apa_table(correlation_matrix, 
          caption = "Correlations of the three different scales assessing conspiracy thinking",
          placement = "h")
```

### Trust in science

Table \@ref(tab:exp4-correlation-trust) shows the correlations of the three different items measuring trust in science.

```{r exp4-correlation-trust}
correlation_matrix <- exp4_wide %>%
  select(wgm_sciencegeneral, wgm_scientists, pew) %>% 
  cor()

apa_table(correlation_matrix, 
          caption = "Correlations of the three different items measuring trust in science",
          placement = "h")
```

## Correlations with alternative measures

Table \@ref(tab:exp4-correlations-outcomes) shows the correlations between knowledge and acceptance, respectively, and outcome variables.

```{r}
# Standardize all variables. Linear regression on standardized variables is equivalent to correlation
standardized_variables <- exp4_wide %>% 
  select(avg_acceptance, avg_knowledge, BCTI_avg, CMQ_avg, SICBS, wgm_scientists, wgm_sciencegeneral, pew) %>% 
  mutate(across(everything(), ~scale(.x)))
```

```{r}
# List of variables
variables <- c("BCTI_avg", "CMQ_avg", "SICBS", "wgm_scientists", "wgm_sciencegeneral", "pew")

# Run regression for each variable and store results in a list
results_list_knowledge <- map(variables, ~ run_regression(standardized_variables, .x, "avg_knowledge"))
results_list_acceptance <- map(variables, ~ run_regression(standardized_variables, .x, "avg_acceptance"))
```

```{r exp4-correlations-outcomes}
# as data frame/output table
results <- bind_rows(list(results_list_knowledge, results_list_acceptance))
results %>% 
  filter(term != "intercept") %>%
  mutate_if(is.numeric, round, digits = 2) %>% 
  # make a combined variable of estimate and p.value
  mutate(estimate = paste0(estimate, " (p", p.value, ")")) %>% 
  select(outcome, term, estimate) %>% 
  pivot_wider(names_from = term, 
              values_from = estimate) %>% 
  rename(`Correlation with knowledge` = avg_knowledge, 
         `Correlation with acceptance` = avg_acceptance, 
  ) %>% 
  mutate(outcome = case_when(outcome == "BCTI_avg" ~ "BCTI \n(main conspiracy measure)", 
                             outcome == "CMQ_avg" ~ "CMQ", 
                             outcome == "SICBS" ~ "SICBS", 
                             outcome == "wgm_scientists" ~ "WGM trust scientists",
                             outcome == "wgm_sciencegeneral" ~ "WGM trust general \n(main trust measure)",
                             outcome == "pew" ~ "PEW trust scientists",
                             )) %>% 
  apa_table(caption = "Correlations between knowledge and acceptance, respectively, and outcome variables")
```

## Results conditional on false responses

Table \@ref(tab:exp4-false-response-regression) shows the correlations between acceptance and outcome variables based on linear regression models on standardized values.

```{r}
# Standardize all variables. Linear regression on standardized variables is equivalent to correlation
standardized_variables <- exp4_false_knowledge %>% 
  select(avg_acceptance, BCTI_avg, CMQ_avg, SICBS, wgm_scientists, wgm_sciencegeneral, pew) %>% 
  mutate(across(everything(), ~scale(.x)))
```

```{r}
# Run regression for each variable and store results in a list
results_list <- setNames(map(variables, ~ run_regression(standardized_variables, .x, "avg_acceptance", return = "model")), variables)
```

```{r exp4-false-response-regression}
modelsummary(results_list, 
             stars = TRUE,
             caption = "Based on false response data only, correlations between acceptance and outcome variables based on linear regression models on standardized values") 
```

## By-question variation

```{r}
# calculate share
plot_data <- exp4_long %>% 
  group_by(subject) %>% 
  summarize(share_true = sum(knowledge == TRUE, na.rm = TRUE)/n(),
            share_accepted = sum(acceptance == "Yes", na.rm = TRUE)/n()) 
```

### Knowledge

(ref:exp4-questions-knowledge) Distribution of correct answers by question. 

```{r exp4-questions-knowledge, fig.cap="(ref:exp4-questions-knowledge)"}
# plot knowledge
ggplot(plot_data, aes(x = reorder(subject, share_true), y = share_true)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(), breaks = seq(0, 1, 0.1)) +
  labs(x = "Question", y = "Share of correct responses") +
  coord_flip()
```

(ref:exp4-questions-acceptance) Distribution of consensus acceptance by question. 

```{r exp4-questions-acceptance, fig.cap="(ref:exp4-questions-acceptance)"}
# plot acceptance
ggplot(plot_data, aes(x = reorder(subject, share_accepted), y = share_accepted)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(), breaks = seq(0, 1, 0.1)) +
  labs(x = "Question", y = "Share of acceptance") +
  coord_flip()
```

## Trust in science

(ref:exp4-trust-scientists) Distribution of trust in scientists. 

```{r exp4-trust-scientists, fig.cap="(ref:exp4-trust-scientists)"}
# calculate share
plot_data <- exp4_wide %>% 
  group_by(wgm_scientists) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  mutate(share = n/sum(n)) %>% 
  rounded_numbers()

# plot knowledge
ggplot(plot_data, aes(x = wgm_scientists, y = share)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format(), breaks = seq(0, 1, 0.1)) +
  labs(x = "Trust in science", y = "Share of participants") +
  geom_text(aes(label = paste0(round(share * 100, 1), "%")),
            position = position_dodge(width = 0.9),
            vjust = -0.5, size = 3) 
```

## Conspiracy thinking

(ref:exp4-conspiracy-distribution) Distribution of conspiracy thinking. 

```{r exp4-conspiracy-distribution, fig.cap="(ref:exp4-conspiracy-distribution)"}
# plot knowledge
ggplot(exp4_wide, aes(x = BCTI_avg)) +
  geom_histogram() +
  labs(x = "Average conspiracy thinking (BCTI)", y = "N")
```

### By-item variation

(ref:exp4-conspiracy-items) Distribution of conspiracy thinking by item. 

```{r exp4-conspiracy-items, fig.cap="(ref:exp4-conspiracy-items)"}
BCTI_data <- exp4_long %>% 
  # bring to long format
  pivot_longer(cols = BCTI_apollo:BCTI_evolution, 
               names_to = "BCTI_item", values_to = "score") %>% 
  select(id, c(starts_with("BCTI"), score)) %>% 
  group_by(BCTI_item) %>% 
  summarize(avg_score = mean(score, na.rm=TRUE)) %>% 
  ungroup()

ggplot(BCTI_data, aes(x = reorder(BCTI_item, avg_score), y = avg_score)) +
    geom_pointrange(aes(ymin = 1, ymax = avg_score),
                  # Make the lines a little thicker and the dots a little bigger
                  fatten = 2, size = 1) +
  scale_y_continuous(limits = c(1, 9), breaks = seq(1, 9, 1)) +
  labs(x = "Conspiracy item", y = "Average score") +
  coord_cartesian(ylim = c(1, 9)) +
  coord_flip()
```

## Reasons for consensus rejection

### All raw answers

```{r exp4-reasons-rejection}
# store all variables
reasons_rejection <- unique(exp4_long$subject)


table <- exp4_wide %>% 
  select(id, all_of(reasons_rejection)) %>% 
  pivot_longer(all_of(reasons_rejection), 
               names_to = "question",
               values_to = "answer") %>% 
  drop_na(answer) %>% 
  arrange(id)

# apa_table(table,
#           align = c("m{1cm}", "m{3cm}", "m{10cm}"), 
#           longtable = TRUE
#           )
kbl(table, booktabs = T, longtable = TRUE,
    caption = "Reasons for consensus rejection") %>%
  kable_paper(full_width = F) %>% 
  column_spec(1) %>%
  column_spec(2) %>%
  column_spec(3, width = "30em") 

```

## Why do people accept the scientific consensus:

### Participants who answered "other"

```{r exp4-other-reasons-acceptance}
# store all variables
table <- exp4_wide %>% 
  select(id, other_reason_agreement) %>% 
  drop_na(other_reason_agreement) %>% 
  arrange(id)

kbl(table, booktabs = T, longtable = TRUE,
    caption = "Reasons for consensus rejection") %>%
  kable_paper(full_width = F) %>% 
  column_spec(1) %>%
  column_spec(2, width = "30em")
```

## How did participants independently verifiy?

### Participants who answered "other"

```{r exp4-independent-verification}
# store all variables
table <- exp4_wide %>% 
  select(id, reason_followup) %>% 
  drop_na(reason_followup) %>% 
  arrange(id)

kbl(table, booktabs = T, longtable = TRUE,
    caption = "Reasons for consensus rejection") %>%
  kable_paper(full_width = F) %>% 
  column_spec(1) %>%
  column_spec(2, width = "30em")
```

## Additional plots

(ref:exp4-conditional-acceptance) Acceptance rates of scientific consensus, based on whether the initial response to the knowledge question was false or true.

```{r exp4-conditional-acceptance, fig.cap="(ref:exp4-conditional-acceptance)"}
plot_data <- exp4_long %>% 
  pivot_longer(c(acceptance, acceptance_initial), 
               names_to = "measure", 
               values_to = "acceptance") %>% 
  # give nicer names
  mutate(measure = case_when(measure == "acceptance" ~ "Acceptance including revisions", 
                             measure == "acceptance_initial" ~ "Initial acceptance"), 
         # make a factor
         measure = factor(measure, levels = unique(measure)[c(2, 1)])
         ) %>% 
  group_by(measure, knowledge, acceptance) %>% 
  count() %>% 
  group_by(measure, knowledge) %>% 
  mutate (share = n/sum(n)) %>% 
  mutate_if(is.numeric, round, digits = 3)

absolute_numbers <- plot_data %>% 
  group_by(measure, knowledge) %>% 
  summarise(n = sum(n))


ggplot(plot_data, aes(x = knowledge, y = share, fill = acceptance)) +
  geom_col(position = "dodge") +
  scale_y_continuous(labels = scales::percent_format(), breaks = seq(0, 1, 0.1)) +
  geom_text(aes(label = paste0(round(share * 100, 1), "%")),
            position = position_dodge(width = 0.9),
            vjust = -0.5, size = 3) +
  scale_fill_viridis_d(option = "cividis") +
  labs(x = "Knowledge answer", fill = "Acceptance \nof consensus") +
  plot_theme +
  geom_bracket(data = absolute_numbers,
               aes(xmin = as.numeric(factor(knowledge)) - 0.4, 
                   xmax = as.numeric(factor(knowledge)) + 0.4, 
                   y.position = 1.05, label =  paste0("n = ", n)),
               inherit.aes = FALSE,
               step.increase = 0) +
  facet_wrap(~measure)
```

(ref:exp4-plot-overview) **A** Shows the distribution of science knowledge (left) and acceptance of scientific consensus for participants who gave the wrong answer **B** Shows the relationship between trust in science and science knowledge/acceptance (if wrong at first, rounded to the first digit) of scientific consensus **C** Shows the relationship between conspiracy thinking and science knowledge/acceptance (if wrong at first) of scientific consensus

```{r exp4-plot-overview, fig.cap="(ref:exp4-plot-overview)", fig.height= 12, fig.width=12}
# Plot distributions of knowledge and acceptance and their mean

mean_value_knowledge <- mean(exp4_wide$avg_knowledge)
max_n <- max(table(exp4_wide$avg_acceptance))

knowledge_mean <- ggplot(exp4_wide, aes(x = avg_knowledge)) +
  geom_bar() + 
  geom_vline(xintercept = mean_value_knowledge, color = "red", linetype = "dashed") +
  geom_text(aes(x = mean_value_knowledge, y = 40, label = paste("Mean =", round(mean_value_knowledge, 2))), 
            vjust = -0.5, hjust = 1.2, check_overlap = TRUE) +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(breaks = seq(0, max_n, 10)) +
  coord_cartesian(xlim = c(0, 1), 
                  ylim = c(0, max_n)) +
  labs(x = "Average science knowledge", 
       y = "N")

mean_value <- mean(exp4_wide$avg_acceptance)

acceptance_mean <- ggplot(exp4_wide, aes(x = avg_acceptance)) +
  geom_bar() + 
  geom_vline(xintercept = mean_value, color = "red", linetype = "dashed") +
  geom_text(aes(x = mean_value, y = 60, label = paste("Mean =", round(mean_value, 2))), 
            vjust = -0.5, hjust = 1.2, check_overlap = TRUE) +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(breaks = seq(0, max_n, 10)) +
  coord_cartesian(xlim = c(0, 1), 
                  ylim = c(0, max_n)) +
  labs(x = "Average consensus acceptance", 
       y = "N")

# Trust in science plots
plot_data <- exp4_wide %>% 
  group_by(wgm_sciencegeneral, avg_knowledge) %>% 
  summarise(n = n())

trust_knowledge <- ggplot(plot_data, aes(x = avg_knowledge, y = wgm_sciencegeneral, fill = n)) +
  geom_tile() +  # Add black border around tiles for better visibility
  geom_jitter(inherit.aes = FALSE, data = exp4_wide, aes(x = avg_knowledge, y = wgm_sciencegeneral),
              width = 0.03, height = 0.08) +  # Scatter points within each tile
  scale_fill_viridis_c(option = "plasma") +  # Use Viridis color scale (Plasma)
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  coord_cartesian(xlim = c(0, 1)) +
  scale_y_continuous(breaks = 1:5) +
  labs(x = "Average science knowledge", 
       y = "Trust in science", 
       fill = "N")

plot_data <- exp4_wide %>% 
  group_by(wgm_sciencegeneral, avg_acceptance) %>% 
  summarise(n = n())


trust_acceptance <- ggplot(plot_data, aes(x = avg_acceptance, y = wgm_sciencegeneral, fill = n)) +
  geom_tile() +  
  geom_jitter(inherit.aes = FALSE, data = exp4_wide, aes(x = avg_acceptance, y = wgm_sciencegeneral),
              width = 0.03, height = 0.08) + 
  scale_fill_viridis_c(option = "plasma") + 
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  coord_cartesian(xlim = c(0, 1)) +
  scale_y_continuous(breaks = 1:5) +
  labs(x = "Average consensus Acceptance", 
       y = "Trust in science", 
       fill = "N") +
  theme(legend.position = "top")

# Conspiracy Belief plot

conspiracy_knowledge <- ggplot(exp4_wide, aes(x = avg_knowledge, y = BCTI_avg)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(breaks = 1:9) +
  coord_cartesian(xlim = c(0, 1), 
                  ylim = c(0, 9)) +
  labs(x = "Average science knowledge", 
       y = "Average conspiracy thinking")

conspiracy_acceptance <- ggplot(exp4_wide, aes(x = avg_acceptance, y = BCTI_avg)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(breaks = 1:9) +
  coord_cartesian(xlim = c(0, 1), 
                  ylim = c(0, 9)) +
  labs(x = "Average consensus acceptance", 
       y = "Average conspiracy thinking") +
  theme(legend.position = "top")

# Combine plots

# distributions
distributions <- ggarrange(knowledge_mean + 
                             rremove("xlab") , 
                           acceptance_mean + 
                             rremove("xlab") +
                             rremove("ylab")) 

# trust
trust <- ggarrange(trust_knowledge + 
                             rremove("xlab") +
                             guides(fill = "none") +
                             labs(caption = NULL) , 
                           trust_acceptance + 
                             rremove("xlab") +
                             rremove("ylab"), 
                   common.legend = TRUE) 

# conspiracy
conspiracy <- ggarrange(conspiracy_knowledge, 
                           conspiracy_acceptance + 
                             rremove("ylab"), 
                   common.legend = TRUE) 


# common plot
patchwork <- (distributions / trust / conspiracy) + 
  plot_annotation(tag_levels = 'A')  

patchwork
```


